{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化模型参数\n",
    "\n",
    "用mlp这个例子初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(nn.Dense(4, activation='relu'))\n",
    "        net.add(nn.Dense(2))\n",
    "    return net\n",
    "\n",
    "x = nd.random.uniform(shape=(3,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不进行初始化，系统会报错，需要初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'sequential0_dense0_bias' has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "try:\n",
    "    net = get_net()\n",
    "    net(x)\n",
    "except RuntimeError as err:\n",
    "    sys.stderr.write(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dense(None -> 4, Activation(relu))\n",
       "  (1): Dense(None -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.00212593 0.00365805]\n",
       " [0.00161272 0.00441845]\n",
       " [0.00204872 0.00352518]]\n",
       "<NDArray 3x2 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 访问模型参数\n",
    "\n",
    "之前我们提到过可以通过`weight`和`bias`访问`Dense`，他们是`Parameter`这个类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:  sequential0_dense0 \n",
      "weight:  Parameter sequential0_dense0_weight (shape=(4L, 5L), dtype=float32) \n",
      "bias:  Parameter sequential0_dense0_bias (shape=(4L,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = net[0].weight\n",
    "b = net[0].bias\n",
    "print 'name: ', net[0].name, '\\nweight: ', w, '\\nbias: ', b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后通过`data`访问参数， `grad`访问对应的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight:  \n",
      "[[-0.06206018  0.06491279 -0.03182812 -0.01631819 -0.00312688]\n",
      " [ 0.0408415   0.04370362  0.00404529 -0.0028032   0.00952624]\n",
      " [-0.01501013  0.05958354  0.04705103 -0.06005495 -0.02276454]\n",
      " [-0.0578019   0.02074406 -0.06716943 -0.01844618  0.04656678]]\n",
      "<NDArray 4x5 @cpu(0)>\n",
      "weight gradient:  \n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "<NDArray 4x5 @cpu(0)>\n",
      "bias:  \n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>\n",
      "bias gradient:  \n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print 'weight: ', w.data()\n",
    "print 'weight gradient: ',w.grad()\n",
    "print 'bias: ', b.data()\n",
    "print 'bias gradient: ', b.grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过`collect_params`来访问`Block`中的所有参数（会包含所有的子Block）。它会返回一个名字到对应的Parameter的dict。可以用正常`[]`，也可以用`get()`，get方法不需要填名字前缀。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential0_ (\n",
      "  Parameter sequential0_dense0_weight (shape=(4L, 5L), dtype=float32)\n",
      "  Parameter sequential0_dense0_bias (shape=(4L,), dtype=float32)\n",
      "  Parameter sequential0_dense1_weight (shape=(2L, 4L), dtype=float32)\n",
      "  Parameter sequential0_dense1_bias (shape=(2L,), dtype=float32)\n",
      ")\n",
      "\n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>\n",
      "\n",
      "[[-0.06206018  0.06491279 -0.03182812 -0.01631819 -0.00312688]\n",
      " [ 0.0408415   0.04370362  0.00404529 -0.0028032   0.00952624]\n",
      " [-0.01501013  0.05958354  0.04705103 -0.06005495 -0.02276454]\n",
      " [-0.0578019   0.02074406 -0.06716943 -0.01844618  0.04656678]]\n",
      "<NDArray 4x5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "params = net.collect_params()\n",
    "print(params)\n",
    "print(params['sequential0_dense0_bias'].data())\n",
    "print(params.get('dense0_weight').data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用不同的初始化函数初始化\n",
    "\n",
    "我们一直使用默认的`initialize`进行初始化权重。它会对所有权重初始化为`[-0.07,0.07]`之间进行均匀分布的随机数。我们可以采用别的初始化方法，比如均值为0，方差为0.02的正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "[[ 0.02804598  0.00220872  0.00701151  0.02721515  0.00500832]\n",
      " [ 0.00112992  0.03227538 -0.01813176 -0.00385197 -0.01286032]\n",
      " [ 0.03360647 -0.02855298 -0.03083278 -0.02110904 -0.02623655]\n",
      " [-0.00293494  0.01282986 -0.01476416  0.04062728  0.01186533]]\n",
      "<NDArray 4x5 @cpu(0)>, \n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>)\n"
     ]
    }
   ],
   "source": [
    "from mxnet import init\n",
    "params.initialize(init=init.Normal(sigma=0.02), force_reinit=True)\n",
    "print(net[0].weight.data(), net[0].bias.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全一函数的初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n",
      "<NDArray 4x5 @cpu(0)>, \n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>)\n"
     ]
    }
   ],
   "source": [
    "params.initialize(init=init.One(), force_reinit=True)\n",
    "print(net[0].weight.data(), net[0].bias.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义一个初始化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_weight:  (4L, 5L)\n",
      "init_weight:  (2L, 4L)\n",
      "\n",
      "[[6.8274803 9.877607  5.08314   9.2790165 6.153712 ]\n",
      " [5.0585704 8.824558  6.7998905 9.720617  8.649953 ]\n",
      " [8.749996  5.8581486 6.697019  7.605183  7.447745 ]\n",
      " [5.27169   6.6949253 5.999983  5.8974514 5.092609 ]]\n",
      "<NDArray 4x5 @cpu(0)>\n",
      "\n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "class Myinit(init.Initializer):\n",
    "    def __init__(self):\n",
    "        super(Myinit, self).__init__()\n",
    "        self._verbose = True\n",
    "    def _init_weight(self, _, arr):\n",
    "        print 'init_weight: ', arr.shape        \n",
    "        nd.random.uniform(low=5, high=10, out=arr)\n",
    "    def _init_bias(self, _, arr):\n",
    "        arr[:] = 2\n",
    "        print 'init_bias: ', arr.shape\n",
    "        \n",
    "        \n",
    "params.initialize(init=Myinit(), force_reinit=True)\n",
    "print net[0].weight.data()\n",
    "print net[0].bias.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 延后初始化\n",
    "\n",
    "Gluon的优势在于不需要指定输入大小，在之后forward就会自动推测参数大小\n",
    "\n",
    "如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential1_ (\n",
      "  Parameter sequential1_dense0_weight (shape=(4, 0), dtype=float32)\n",
      "  Parameter sequential1_dense0_bias (shape=(4,), dtype=float32)\n",
      "  Parameter sequential1_dense1_weight (shape=(2, 0), dtype=float32)\n",
      "  Parameter sequential1_dense1_bias (shape=(2,), dtype=float32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = get_net()\n",
    "print(net.collect_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们初始化,并没有看到Myinit打印的东西，由于我们仍然不知道形状。真正的初始化会在我们看到数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize(init=Myinit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_weight:  (4L, 5L)\n",
      "init_weight:  (2L, 4L)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[864.09644 684.8019 ]\n",
       " [871.0519  691.282  ]\n",
       " [696.2539  554.8877 ]]\n",
       "<NDArray 3x2 @cpu(0)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到已经有参数 输入数了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential1_ (\n",
      "  Parameter sequential1_dense0_weight (shape=(4L, 5L), dtype=float32)\n",
      "  Parameter sequential1_dense0_bias (shape=(4L,), dtype=float32)\n",
      "  Parameter sequential1_dense1_weight (shape=(2L, 4L), dtype=float32)\n",
      "  Parameter sequential1_dense1_bias (shape=(2L,), dtype=float32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net.collect_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 避免延后初始化\n",
    "\n",
    "有时候我们不想延后初始化，这时候需要创建网络的时候指定输入大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_weight:  (4L, 5L)\n",
      "init_weight:  (2L, 4L)\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(4, in_units=5, activation='relu'))\n",
    "    net.add(nn.Dense(2, in_units=4))\n",
    "    \n",
    "net.initialize(Myinit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享模型参数\n",
    "\n",
    "有时候我们想在层之间共享同一份参数，我们可以通过Block的`params`输出参数手动指定参数，而不是让系统自动生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_weight:  (4L, 5L)\n",
      "init_weight:  (2L, 4L)\n",
      "Sequential(\n",
      "  (0): Dense(5 -> 4, Activation(relu))\n",
      "  (1): Dense(5 -> 4, Activation(relu))\n",
      "  (2): Dense(4 -> 2, linear)\n",
      ")\n",
      "\n",
      "[[7.598556  8.144909  5.0002766 9.363254  6.5593014]\n",
      " [6.36771   7.127258  8.990234  9.426688  5.9281797]\n",
      " [8.399397  9.763958  7.2806487 8.437441  7.417043 ]\n",
      " [6.0775385 8.943697  9.736853  6.147209  8.65428  ]]\n",
      "<NDArray 4x5 @cpu(0)>\n",
      "\n",
      "[[7.598556  8.144909  5.0002766 9.363254  6.5593014]\n",
      " [6.36771   7.127258  8.990234  9.426688  5.9281797]\n",
      " [8.399397  9.763958  7.2806487 8.437441  7.417043 ]\n",
      " [6.0775385 8.943697  9.736853  6.147209  8.65428  ]]\n",
      "<NDArray 4x5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(4, in_units=5, activation='relu'))\n",
    "    net.add(nn.Dense(4, in_units=5, activation='relu', params=net[-1].params))\n",
    "    net.add(nn.Dense(2, in_units=4))\n",
    "    \n",
    "net.initialize(Myinit())\n",
    "print net\n",
    "print net[0].weight.data()\n",
    "print net[1].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential5_ (\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
